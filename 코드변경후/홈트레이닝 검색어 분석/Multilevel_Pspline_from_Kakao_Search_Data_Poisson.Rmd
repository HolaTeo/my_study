---
title: "Multilevel Pspline from Kakao Search Data"
author: "Choi TaeYoung"
date: "`r format(Sys.Date(), '%Y-%m-%d')`"
output:
  bookdown::pdf_document2:
    latex_engine: xelatex
  pdf_document:
    latex_engine: xelatex
    toc: yes
  word_document:
    toc: yes
header-includes:
- \usepackage{kotex}
- \usepackage{fontspec}
- \usepackage{unicode-math}
mainfont: NanumGothic
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
 
# 필요한 패키지
```{r message=FALSE, warning=FALSE, include=FALSE}
#for data
library(tidyverse)
library(tidyr)
library(devtools)
library(MASS)
library(lubridate)
library(quantmod)
# library(PerformnceAnalytics)
library(magrittr)
library(dplyr)
library(data.table)
 
# for graph
library(ggplot2)
library(dygraphs)
library(highcharter)
 
# for model
library(pscl)
library(pspline)
```


```{r message=FALSE, warning=FALSE, include=FALSE}

#' generate simulated response for multilevel splines
#'
#' Generates simulated response for multilevel splines
#'
#' @author YD Hwang \email{yhwang@@g.skku.edu} and ER Lee \email{erlee@@skku.edu}
#' @importFrom stats coef glm lm rbinom rnorm vcov
#' @param J  number of 'data' intervals
#' @param mod  underlying model; either `lm` or `glm`
#' @param x_sigma  design matrix sigma
#' @param e_sigma  error variance - around the mean function; data level.
#' @param z_sigma  error variance around my surface; structural level.
#' @param N_s the minimum sample size for each interval.
#' @param N_m  the maximum sample size for each interval; default = 200.
#' @return returns a list described above.
#' @format list(x_list = x_list, y_list = y_list, e_list = e_list, true_mu = mu, z = z)
#' \describe{
#'   \item{x_list}{the length-J list of design matrices. The nrow of each element is between N_s and N_m}
#'   \item{y_list}{the length-J list of response vectors. The length of each element is between N_s and N_m.}
#'   \item{e_list}{the length-J list of error vectors. The length of each element is between N_s and N_m.}
#'   \item{true_mu}{the true mu vector of length J}
#'   \item{z}{the grid vector of length J}
#' }
#' @export

generate_response <- function(J, mod, e_sigma = 1, x_sigma = 1, z_sigma = 0.5, N_s, N_m = 200) {

  # currently the data interval (z interval) is set to be between -3 and 3.

  n <- sample(N_s:N_m, J, replace = TRUE)

  # smooth surface: z is the grid sequence and mu is the generated smooth function.
  z <- seq(from = -3, to = 3, length.out = J)
  mu <- z^2 - 10 * cos(2 * pi * z)  # "true" surface.

  beta_1 <- mu + rnorm(J, 0, z_sigma)  # slope
  beta_0 <- 0  # intercept

  x_list <- lapply(n, rnorm, mean = 0, sd = x_sigma)
  e_list <- lapply(n, rnorm, mean = 0, sd = e_sigma)

  # outcome generation function; gives 'y' list given e, beta_0, beta_1, and
  # x (design matrix)
  # for glm: logit link binary p(y = 1) = 1/(1 + exp(-beta_0 - beta_1 * x - e)
  # for lm: ordinary linear model structure y = xb + e
  if (mod == "glm") {
    y_list <- mapply(function(x, e, b, beta_0 = 0)
      rbinom(length(x), 1, 1/(1 + exp(-beta_0 - b * x - e))),
      x = x_list, e = e_list, b = beta_1)
  }
  if (mod == "lm") {
    y_list <- mapply(function(x, e, b, beta_0 = 0)
      beta_0 + b * x + e, x = x_list, e = e_list, b = beta_1)
  }
  list(x_list = x_list, y_list = y_list, e_list = e_list, true_mu = mu, z = z)
}

#' Builds ``granular'' data
#'
#' obtains the regression slope and its variance
#' certainly not optimal but this step shouldn't take long regardless
#' @author YD Hwang \email{yhwang@@g.skku.edu} and ER Lee \email{erlee@@skku.edu}
#' @param x_k design matrix
#' @param y_k response vector
#' @param mod underlying model; either `lm` or `glm`
#' @export


granular <- function(x_k, y_k, mod) {
  # summarizing the regression part
  if (mod == "glm")
    fit_lm <- glm(y_k ~ x_k, family = "binomial")
  if (mod == "lm")
    fit_lm <- lm(y_k ~ x_k)

  kth_beta_hat <- coef(fit_lm)[2]
  kth_var <- diag(vcov(fit_lm))[2]
  grain_out <- list(kth_beta_hat, kth_var)
  grain_out
}

#' Generates kerel matrix
#'
#' Generates kernel matrix of J by J, where J = length(z) for multilevel splines
#' certainly not optimal but this step shouldn't take long regardless.
#' Used the formulation from Reinsch (1967).
#' @author YD Hwang \email{yhwang@@g.skku.edu} and ER Lee \email{erlee@@skku.edu}
#' @param z Mid-interval value vector, it is safe to assume this to be equi-distant, but in principle it doesn't have to be. it's not tested though.
#' @export

make_K <- function(z) {
  J <- length(z)
  Del <- matrix(0, nrow = J - 2, ncol = J)
  W <- matrix(0, nrow = J - 2, ncol = J - 2)
  h <- diff(z)
  for (l in 1:(J - 2)) {
    Del[l, l] <- 1/h[l]
    Del[l, (l + 1)] <- -1/h[l] - 1/h[(l + 1)]
    Del[l, (l + 2)] <- 1/h[(l + 1)]
    W[(l - 1), l] <- W[l, (l - 1)] <- h[l]/6
    W[l, l] <- (h[l] + h[l + 1])/3
  }
  K <- t(Del) %*% solve(W) %*% Del
  K
}


#' Main EM function
#'
#' Running EM for multilevel splines
#' certainly not optimal...
#' @author YD Hwang \email{yhwang@@g.skku.edu} and ER Lee \email{erlee@@skku.edu}
#' @param beta_hat_vec data vector of length J
#' @param V covariance matrix of size J by J
#' @param K kernel matrix from `make_K`
#' @param lambda tuning parameter
#' @param maxit maximum iteration number
#' @export


main_EM <- function(beta_hat_vec, V, K, lambda, maxit = 500) {

  # parameter initilization
  eps <- 1000  # convergence tracker
  tol <- 1e-05  # convergence threshold
  sigma2_m <- mean(diag(V))
  J <- length(beta_hat_vec)
  mu_m <- rep(mean(beta_hat_vec), J)
  I <- diag(J)
  iter <- 1

  while (eps > tol & iter <= maxit) {
    # .. EM starts here
    mu_m_old <- mu_m
    sigma2_m_old <- sigma2_m  # current sigma^2

    Vst <- solve(solve(V) + (1/sigma2_m) * diag(J))  # Vst
    D_m <- Vst %*% solve(V)  #D_m <- part_cov %*% V
    mu_m <- solve(D_m + lambda * K) %*% D_m %*% beta_hat_vec

    S_lambda <- solve(I %*% D_m %*% I + lambda * K) %*% I %*% D_m
    effective_df <- sum(diag(S_lambda))

    sigma2_m <- mean((beta_hat_vec - mu_m)^2)
    eps <- sum(abs(mu_m - mu_m_old)) + abs(sigma2_m_old - sigma2_m)
    iter <- iter + 1
    if (iter == maxit) {
      cat("for lambda =", lambda, "max iteration reached; may need to double check \n")
    }
  }  # end of EM .. convergence reached.

  BIC <- sum((beta_hat_vec - mu_m)^2)/(J^(1 - effective_df/J))
  GCV <- sum((beta_hat_vec - mu_m)^2)/(J - effective_df)^2 * J

  EM_out <- list(mu = mu_m, S_lambda = S_lambda, sigma2 = sigma2_m, BIC = BIC, GCV = GCV)
  EM_out
}

#' Naive strawman
#'
#' Running naive splines
#' @author YD Hwang \email{yhwang@@g.skku.edu} and ER Lee \email{erlee@@skku.edu}
#' @param beta_hat_vec data vector of length J
#' @param K kernel matrix from `make_K`
#' @param lambda tuning parameter
#' @export

naive_ss <- function(beta_hat_vec, lambda, K) {

  J <- length(beta_hat_vec)
  I <- diag(J)
  S_lambda <- solve(I + lambda * K)
  f_hat <- S_lambda %*% beta_hat_vec

  eff_df <- sum(diag(S_lambda))

  GCV <- sum((beta_hat_vec - f_hat)^2)/(J - eff_df)^2 * J
  BIC <- log(mean((beta_hat_vec - f_hat)^2)) + eff_df * log(J)/J

  out <- list(mu = f_hat, S_lambda = S_lambda, BIC = BIC, GCV = GCV)
  out
}


#' Generates simulated response for multilevel splines -- test function #2
#'
#' @author YD Hwang \email{yhwang@@g.skku.edu} and ER Lee \email{erlee@@skku.edu}
#' @importFrom stats coef glm lm rbinom rnorm vcov
#' @param J  number of 'data' intervals
#' @param mod  underlying model; either `lm` or `glm`
#' @param x_sigma  design matrix sigma
#' @param e_sigma  error variance - around the mean function; data level.
#' @param z_sigma  error variance around my surface; structural level.
#' @param N_s the minimum sample size for each interval.
#' @param N_m  the maximum sample size for each interval; default = 200.
#' @return returns a list described above.
#' @format list(x_list = x_list, y_list = y_list, e_list = e_list, true_mu = mu, z = z)
#' \describe{
#' This function is supposed to be combined with the other generation function.. but later.
#'   \item{x_list}{the length-J list of design matrices. The nrow of each element is between N_s and N_m}
#'   \item{y_list}{the length-J list of response vectors. The length of each element is between N_s and N_m.}
#'   \item{e_list}{the length-J list of error vectors. The length of each element is between N_s and N_m.}
#'   \item{true_mu}{the true mu vector of length J}
#'   \item{z}{the grid vector of length J}
#' }
#' @export

generate_response_smooth <- function(J, mod, e_sigma = 1, x_sigma = 1, z_sigma = 0.5, N_s, N_m = 200) {

  # currently the data interval (z interval) is set to be between 0 and 1

  n <- sample(N_s:N_m, J, replace = TRUE)

  # smooth surface: z is the grid sequence and mu is the generated smooth function.
  z <- seq(from = 0, to = 1, length.out = J)
  mu <- sin(12*(z + 0.2)) / (z + 0.2)  # "true" surface.

  beta_1 <- mu + rnorm(J, 0, z_sigma)  # slope
  beta_0 <- 0  # intercept

  x_list <- lapply(n, rnorm, mean = 0, sd = x_sigma)
  e_list <- lapply(n, rnorm, mean = 0, sd = e_sigma)

  # outcome generation function; gives 'y' list given e, beta_0, beta_1, and
  # x (design matrix)
  # for glm: logit link binary p(y = 1) = 1/(1 + exp(-beta_0 - beta_1 * x - e)
  # for lm: ordinary linear model structure y = xb + e
  if (mod == "glm") {
    y_list <- mapply(function(x, e, b, beta_0 = 0)
      rbinom(length(x), 1, 1/(1 + exp(-beta_0 - b * x - e))),
      x = x_list, e = e_list, b = beta_1)
  }
  if (mod == "lm") {
    y_list <- mapply(function(x, e, b, beta_0 = 0)
      beta_0 + b * x + e, x = x_list, e = e_list, b = beta_1)
  }
  list(x_list = x_list, y_list = y_list, e_list = e_list, true_mu = mu, z = z)
}

# GetDiffMatrix() ---------------------------------------------------------
#' Get Difference Matrix
#'
#' Calculates the difference matrix of order 2 (ISSUE -- Only gets difference
#'   matrix of order 2 for now).
#'
#' @param nr Number of rows the difference matrix will have.
#' @param ord Order of the difference matrix.
#'
#' @return A difference matrix of order \code{ord} with dimensions \code{nr}
#'   by \eqn{\code{nr} + \code{ord}}
#'
#' @export
#'
```


```{r message=FALSE, warning=FALSE, include=FALSE}
GetDiffMatrix <- function(nr, ord = 2) {
  # Set up difference matrix
  D <- matrix(0, nrow = nr, ncol = nr + ord)
  
  # Determine first row
  FRow <- c(c(1, -2, 1), rep(0, nr + ord - 3))
  
  # Fill in diff. matrix
  for (i in 1:nr) D[i, ] <- CPerm(FRow, i - 1)
  
  return(D)
}
# CPerm() -----------------------------------------------------------------
#' Cyclic Permuatation
#'
#' Get cyclic permutation of vector. Can can the function multiple times
#'   through the use of the \code{i} argument.
#'
#' @param x Vector to be cycled through
#' @param i Number of cyclic permutations
#'
#' @return Vector with all elements moved \code{i} spaces to the left with
#'   end elements wrapping around.
#'
#' @export
#'
CPerm <- function(x, i = 1) {
  if(i == 0) {
    return(x)
  } else {
    LastElement <- utils::tail(x,1)
    CycledX <- c(LastElement, utils::head(x,-1))
    return(CPerm(CycledX, i - 1))
  }
}
# GetBSpline() ------------------------------------------------------------
#' Get B-Spline Matrix
#'
#' Generates B-Spline functions over some parameters and places such functions
#'   into columns of a \eqn{n} by \eqn{(m + deg + 1)} matrix.
#'
#' @param x Range of values to define the function over.
#' @param deg Degree of the desired B-Spline.
#' @param IntKnots Interior knots that partially define the B-Spline.
#' @param ExtKnots Exterior knots, often \code{ExtKnots = c(min(x),max(x))}.
#'
#' @return Matrix where \eqn{i,j}-th entry corresponds to \eqn{j}-th basis
#'   function evaluated at \eqn{i}-th data point.
#'
#' @export
#'
GetBSpline <- function(x, deg = 3, IntKnots, ExtKnots) {
  # Augment exterior knots around interior knots
  AugKnots <- c(rep(ExtKnots[1], deg + 1), IntKnots, rep(ExtKnots[2], deg + 1))
  
  # Expect m+k basis functions, call this integer "NumF"
  NumF <- length(IntKnots) + (deg + 1)
  
  # Fill matrix columns with basis functions
  B <- matrix(0, length(x), NumF)
  for (i in 1:NumF) B[,i] <- PSplinesR::GetBasis(x, deg, AugKnots, i)
  
  # Manually add in boundary to final basis function
  if(any(x == ExtKnots[2])) B[x == ExtKnots[2], NumF] <- 1
  return(B)
}

#library(devtools)
#devtools::install_github("nclJoshCowley/PSplinesR", force = T)

#' Main EM function using pspline
#' 
#'
```


```{r message=FALSE, warning=FALSE, include=FALSE}

MultiEM_ps <- function(x, beta_hat_vec, V, lambda, maxit = 5000) {
  # parameter initilization
  eps <- 10  # convergence tracker
  tol <- 1e-05  # convergence threshold
  J <- length(x)
  I <- diag(J)
  IK <- x[-c(1, J)]
  EK <- x[c(1, J)]
  sigma2_m <- mean(diag(V))
  mu_m <- rep(mean(beta_hat_vec), J)
  
  # Get natural cubic B-spline
  B <- PSplinesR::GetBSpline(x, deg = 3, IK, EK)
  # 
  # # Get difference matrix (see DiffMatrix.R)
  D <- GetDiffMatrix(dim(B)[1], 2)
  
  iter <- 1
  while (eps > tol & iter <= maxit) {
    # .. EM starts here
    mu_m_old <- mu_m
    sigma2_m_old <- sigma2_m  # current sigma^2
    
    Vst <- solve(solve(V) + (1/sigma2_m) * diag(J))  # Vst
    D_m <- Vst %*% solve(V)  #D_m <- part_cov %*% V
    mu_m <- B%*%solve(t(B)%*%D_m%*%B + lambda * t(D)%*%D,tol=1e-30) %*%t(B)%*% D_m %*% beta_hat_vec
    
    S_lambda <- B%*%solve(t(B)%*%D_m%*%B + lambda * t(D)%*%D, tol=1e-30) %*% t(B) %*% D_m
    AlphaEst <-  solve((t(B) %*% B) + lambda * t(D) %*% D) %*% t(B) %*% beta_hat_vec
    
    effective_df <- sum(diag(S_lambda))
    sigma2_m <- mean((beta_hat_vec - mu_m)^2)
    
    eps <- sum(abs(mu_m - mu_m_old)) + abs(sigma2_m_old - sigma2_m)
    iter <- iter + 1
    if (iter == maxit) {
      cat("for lambda =", lambda, "max iteration reached; may need to double check \n")
    }
  }  # end of EM .. convergence reached.
  
  BIC <- sum((beta_hat_vec - mu_m)^2)/(J^(1 - effective_df/J))
  GCV <- sum((beta_hat_vec - mu_m)^2)/(J - effective_df)^2 * J

  YVarEst <- sigma2_m * (S_lambda %*% t(S_lambda))
  
  EM_out <- list(AlphaEst=AlphaEst, YVarEst=YVarEst, mu = mu_m, S_lambda = S_lambda, sigma2 = sigma2_m, BIC = BIC, GCV = GCV)
  EM_out
}

# Naive Method in P-spline

naive_ps <- function(x, beta_hat_vec, lambda) {
  # Get natural cubic B-spline
  J <- length(x)
  I <- diag(J)
  IK <- x[-c(1, J)]
  EK <- x[c(1, J)]
  B <- PSplinesR::GetBSpline(x, deg = 3, IK, EK)

  # Get difference matrix (see DiffMatrix.R)
  D <- GetDiffMatrix(dim(B)[1], 2)

  # Calculate \hat{\bm{\alpha} and Hat matrix
  S_lambda <- B %*% solve((t(B) %*% B) + lambda * t(D) %*% D) %*% t(B)
  AlphaEst <-  solve((t(B) %*% B) + lambda * t(D) %*% D) %*% t(B) %*% beta_hat_vec
  betaEst <- S_lambda %*% beta_hat_vec
  
  eff_df <- sum(diag(S_lambda))
  
  # Using theory from Molinair (2014) and LaTeX doc.
  GCV <- sum((beta_hat_vec - betaEst)^2)/(J - eff_df)^2 * J
  BIC <- log(mean((beta_hat_vec - betaEst)^2)) + eff_df * log(J)/J
  
  Sig2Est <- sum((beta_hat_vec - betaEst)^2) / (J - sum(diag(S_lambda)))
  YVarEst <- Sig2Est * (S_lambda %*% t(S_lambda))

  out <- list(AlphaEst = AlphaEst,
              betaEst = as.vector(t(betaEst)),
              YVarEst = YVarEst,
              mu = betaEst, S_lambda = S_lambda, BIC = BIC, GCV = GCV)
  out
}

# Graphic of Plot
# YEst 역할 : betaEst in naive_ps fnc
# YVarEst 역할 : YVarEst
# 

PlotPSplineFit <- function(x, y, lambda, CI = 0.95, ...) {
  # Plot original data
  graphics::plot(x, y, pch = 4, ...)

  # Calculate SE
  fit <- PSplinesR::FitPSpline(x, y, lambda)
  SE <- stats::qnorm(0.5 * (CI + 1)) * sqrt(diag(fit$YVarEst))

  # Calculate fitted values with CI values
  toPlot <- list(mean = fit$YEst, lower = fit$YEst - SE, upper = fit$YEst + SE)

  ## CI
  graphics::polygon(c(x, rev(x)), c(toPlot$lower, rev(toPlot$upper)),
          col = "grey75", border = F)
  # Re-add points over polygon
  graphics::points(x, y, pch = 4)
  ## Fitted line
  graphics::lines(x, toPlot$mean)
}
```
\newpage
 
# 데이터
- Y data : Y데이터의 경우 149주(2018년 1월 ~ 2020년 8월)동안의 카카오로 "홈트레이닝"을 검색한 횟수를 지역별로 나타냄
 
- X data :  X데이터의 경우 17개의 지역별 인구수


```{r message=FALSE, warning=FALSE, include=FALSE}
# Y data
obs_y <- fread("HT_kakao_search.csv")
z_month <- unlist(obs_y[-1,2]) %>% scale()

# X data
x_pop <- obs_y[1,3:19] %>% t()

# X, y 데이터
x_list <- x_pop %>% as.data.frame() %>% unlist() %>% as.list()
y_list <- obs_y[-1,3:19] %>% t() %>% as.data.frame()
```

\newpage

# Multilevel 모델에 적용

- 논문의 방법인 EM알고리즘을 통해 multilevel spline 방법으로 최적의 $\mu$ 벡터를 찾았다.

```{r}
#multilevel

  #beta_hat_vector 구하기

  grain_out <- NULL
  J=149
  beta_hat <- NULL
  for(m in 1:149){
    result2_out <- NULL
    results2 <- glm(unlist(y_list[m]) ~ unlist(x_list), family = poisson,maxit=2000)
      kth_beta_hat <- coef(results2)[2]
      kth_var <- diag(vcov(results2))[2]
      grain_out <- list(kth_beta_hat, kth_var)
      grain_out
    beta_hat <- rbind(beta_hat,grain_out)
  }
```
 
 
- p-spline 기법을 활용하여 새롭게 짠 코드로 리얼데이터에 적용

```{r}
EM_out <- MultiEM_ps(x=z_month,
                     beta_hat_vec=unlist(beta_hat[,1]),
                     V=diag(unlist(beta_hat[,2])),
                     lambda=1)
tail(EM_out$mu)
```
 
\newpage
## Naive's GCV vector 찾기
 
- Multilevel과 성능을 비교하기위해서 Naive한 방법으로 구해보자.
- Naive기법 역시 P-spline으로 코드를 짠 후 실행했다.

```{r}
naive_out <- naive_ps(x=z_month,
                      beta_hat_vec=unlist(beta_hat[,1]),
                      lambda = 500)
tail(naive_out$mu)
```

# 그래프

```{r}
# hat_all
single_beta <- unlist(beta_hat[,1]) %>% as.vector()
mu_z_multi <- EM_out$mu %>% as.vector()

#mu_z_naive <- naive_out$mu %>% as.vector()
test_mon <- fread("HT_kakao_search.csv")
test_mon <- test_mon[-1,1]

mu_z <- cbind(obs_y[-1,2],mu_z_multi) %>% as.data.frame
mu_z <- rename(mu_z, Week = V2)

# naive

df2 <- cbind(test_mon,single_beta)
df2 <- rename(df2, Week =V1)

df2_naive <- naive_out$betaEst
df2 <- cbind(df2,df2_naive)
df2 <- rename(df2, Naive =df2_naive)

df2 <- cbind(df2,mu_z$mu_z_multi)
df2 <- rename(df2, Multi =V2)

# gather함수 사용
df2 <- gather(df2[, c("Week",  "single_beta", "Naive", "Multi")],
             key = "Method", value = "mu_z", -Week)
df2$Week <- parse_date_time(df2$Week, "ymd")
df2$Week <- as.Date(df2$Week, format="%Y-%m-%d")

g <- ggplot(df2, aes(x=Week, y=mu_z, group=Method)) +
  geom_line(data= df2 %>% dplyr::filter(Method != "single_beta"),aes(x = Week, y = mu_z, color = Method, linetype = Method, group=Method)) +
  geom_point(data=df2 %>% dplyr::filter(Method == "single_beta"), aes(x = Week, y = single_beta, color = "single_beta")) +
  guides(linetype = "none") +
  scale_color_discrete(name = "Method")
g
```